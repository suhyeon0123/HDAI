{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import xmltodict\n",
    "import base64\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lead(path):\n",
    "    with open(path, 'rb') as xml:\n",
    "        ECG = xmltodict.parse(xml.read().decode('utf8'))\n",
    "    \n",
    "    augmentLeads = True\n",
    "    if path.split('/')[-1][0] == '5':\n",
    "        waveforms = ECG['RestingECG']['Waveform'][1]\n",
    "    elif path.split('/')[-1][0] == '6':\n",
    "        waveforms = ECG['RestingECG']['Waveform']\n",
    "        augmentLeads = False\n",
    "    else:\n",
    "        waveforms = ECG['RestingECG']['Waveform']\n",
    "    \n",
    "    leads = {}\n",
    "    \n",
    "    for lead in waveforms['LeadData']:\n",
    "        lead_data = lead['WaveFormData']\n",
    "        lead_b64  = base64.b64decode(lead_data)\n",
    "        lead_vals = np.array(array.array('h', lead_b64))\n",
    "        leads[ lead['LeadID'] ] = lead_vals\n",
    "    \n",
    "    if augmentLeads:\n",
    "        leads['III'] = np.subtract(leads['II'], leads['I'])\n",
    "        leads['aVR'] = np.add(leads['I'], leads['II'])*(-0.5)\n",
    "        leads['aVL'] = np.subtract(leads['I'], 0.5*leads['II'])\n",
    "        leads['aVF'] = np.subtract(leads['II'], 0.5*leads['I'])\n",
    "    \n",
    "    return leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_2_003469_ecg.xml\n",
      "8_2_001879_ecg.xml\n",
      "6_2_003618_ecg.xml\n",
      "8_2_002164_ecg.xml\n",
      "6_2_005055_ecg.xml\n",
      "8_2_007281_ecg.xml\n",
      "8_2_008783_ecg.xml\n",
      "8_2_007226_ecg.xml\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "error_train = ['6_2_003469_ecg.xml', '6_2_003618_ecg.xml', '6_2_005055_ecg.xml', '8_2_001879_ecg.xml', '8_2_002164_ecg.xml']\n",
    "error_valid = ['8_2_007281_ecg.xml', '8_2_008783_ecg.xml', '8_2_007226_ecg.xml']\n",
    "\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "valid_data = []\n",
    "valid_labels = []\n",
    "\n",
    "\n",
    "train_pathes = ['data/train/arrhythmia/', 'data/train/normal/']\n",
    "valid_pathes = ['data/validation/arrhythmia/', 'data/validation/normal/']\n",
    "\n",
    "error_decode = []   # 디코딩에 실패한 데이터들..\n",
    "# error_len = [] # 5000, 4999개를 맞추지 못한 데이터들.. 혹은 12개의 lead가 아닌것들..\n",
    "\n",
    "# train data\n",
    "for path in train_pathes:\n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        if file in error_train:\n",
    "            print(file)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            data = get_lead(path + file)\n",
    "        except Exception as e:\n",
    "            error_decode.append(path + file)\n",
    "        \n",
    "        listed_data = []\n",
    "        keys = sorted(data.keys())\n",
    "        for key in keys:\n",
    "            listed_data.append(data[key])\n",
    "        \n",
    "        flag = False\n",
    "        for idx, i in enumerate(listed_data):\n",
    "            if len(i) == 5000:\n",
    "                continue\n",
    "            elif len(i) == 4999:\n",
    "                listed_data[idx] = np.append(i, 0)\n",
    "            else:\n",
    "                flag = True\n",
    "        if flag:\n",
    "            continue\n",
    "        \n",
    "        train_data.append(listed_data)\n",
    "        if 'arrhythmia' in path:\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            train_labels.append(0)\n",
    "            \n",
    "# valid data\n",
    "for path in valid_pathes:\n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        if file in error_valid:\n",
    "            print(file)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            data = get_lead(path + file)\n",
    "        except Exception as e:\n",
    "            error_decode.append(path + file)\n",
    "        \n",
    "        listed_data = []\n",
    "        keys = sorted(data.keys())\n",
    "        for key in keys:\n",
    "            listed_data.append(data[key])\n",
    "        \n",
    "        valid_data.append(listed_data)\n",
    "        if 'arrhythmia' in path:\n",
    "            valid_labels.append(1)\n",
    "        else:\n",
    "            valid_labels.append(0)\n",
    "\n",
    "print(len(error_decode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_lead_len = []\n",
    "for idx, i in enumerate(train_data):\n",
    "    if len(i) != 12:\n",
    "        error_lead_len.append(idx)\n",
    "for i in error_lead_len:\n",
    "    del train_data[i]\n",
    "    del train_labels[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 길이 및 lead 개수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "524436\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 길이 분포 확인: valid는 모두 5000인것을 확인\n",
    "# train은 60912개가 4999, 36개가 1249, 1개가 4988\n",
    "# 위의 테스크는 먼저 4999개만 0의 패딩을 붙이고 나머지는 제외하는식으로 전처리함\n",
    "\n",
    "c4999 = 0\n",
    "c5000 = 0\n",
    "cx = 0\n",
    "\n",
    "for i in train_data:\n",
    "    for j in i:\n",
    "        if len(j) == 4999:\n",
    "            c4999 +=1\n",
    "        elif len(j) == 5000:\n",
    "            c5000 +=1\n",
    "        else:\n",
    "            cx +=1\n",
    "\n",
    "for i in valid_data:\n",
    "    for j in i:\n",
    "        if len(j) == 4999:\n",
    "            c4999 +=1\n",
    "        elif len(j) == 5000:\n",
    "            c5000 +=1\n",
    "        else:\n",
    "            cx +=1\n",
    "\n",
    "print(c4999)\n",
    "print(c5000)\n",
    "print(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43703\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 딱 한개의 9 lead의 데이터가 존재한다..\n",
    "v12 = 0\n",
    "v9 = 0\n",
    "vx = 0\n",
    "\n",
    "for i in train_data:\n",
    "    if len(i) == 12:\n",
    "        v12 +=1\n",
    "    elif len(i) == 9:\n",
    "        v9 += 1\n",
    "    else:\n",
    "        vx +=1\n",
    "        \n",
    "for i in valid_data:\n",
    "    if len(i) == 12:\n",
    "        v12 +=1\n",
    "    elif len(i) == 9:\n",
    "        v9 += 1\n",
    "    else:\n",
    "        vx +=1\n",
    "print(v12)\n",
    "print(v9)\n",
    "print(vx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels))\n",
    "valid_dataset = torch.utils.data.TensorDataset(torch.tensor(valid_data).float(), torch.tensor(valid_labels))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual과 dropout 추가 필요\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, drop_out=0.0):\n",
    "        super(Classifier,self).__init__()\n",
    "        self.cnn1 = nn.Conv1d(in_channels=12, out_channels=32, kernel_size=5, padding=2) \n",
    "        self.cnn2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.cnn3 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=5, padding=2)\n",
    "    \n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.pool2 = nn.MaxPool1d(5)\n",
    "        self.pool3 = nn.MaxPool1d(5)\n",
    "        \n",
    "    \n",
    "        self.fc1 = nn.Linear(64 * 50, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.drop_out = nn.Dropout(p=drop_out)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.cnn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.cnn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.cnn3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 64*50)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        \n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x.view(-1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Classifier(drop_out=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bang/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train \t\t loss mean 0.6010642647743225 accuracy: 0.738466687261868\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.5322439670562744 accuracy: 0.8989504013171434 \n",
      "\n",
      "epoch: 1\n",
      "train \t\t loss mean 0.5011196732521057 accuracy: 0.8775615281639378\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.46328073740005493 accuracy: 0.9308499691294505 \n",
      "\n",
      "epoch: 2\n",
      "train \t\t loss mean 0.4716271162033081 accuracy: 0.9046699618988776\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.4443812668323517 accuracy: 0.9405227413047952 \n",
      "\n",
      "epoch: 3\n",
      "train \t\t loss mean 0.456778347492218 accuracy: 0.9192668108330759\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.4357840418815613 accuracy: 0.9567812307059066 \n",
      "\n",
      "epoch: 4\n",
      "train \t\t loss mean 0.44684261083602905 accuracy: 0.9277623313767892\n",
      "validataion \t loss mean 0.43007659912109375 accuracy: 0.953282568429718 \n",
      "\n",
      "epoch: 5\n",
      "train \t\t loss mean 0.44022509455680847 accuracy: 0.9347389558232931\n",
      "validataion \t loss mean 0.4352411925792694 accuracy: 0.9438155999176785 \n",
      "\n",
      "epoch: 6\n",
      "train \t\t loss mean 0.4349527359008789 accuracy: 0.9378282360210071\n",
      "validataion \t loss mean 0.43038687109947205 accuracy: 0.9483432805103931 \n",
      "\n",
      "epoch: 7\n",
      "train \t\t loss mean 0.4319949746131897 accuracy: 0.9407115642055401\n",
      "validataion \t loss mean 0.4328193962574005 accuracy: 0.9481374768470878 \n",
      "\n",
      "epoch: 8\n",
      "train \t\t loss mean 0.42783114314079285 accuracy: 0.9448563484708064\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.4240107834339142 accuracy: 0.9608973039720107 \n",
      "\n",
      "epoch: 9\n",
      "train \t\t loss mean 0.425857275724411 accuracy: 0.9468386365976728\n",
      "validataion \t loss mean 0.4475599229335785 accuracy: 0.9538999794196337 \n",
      "\n",
      "epoch: 10\n",
      "train \t\t loss mean 0.4221302270889282 accuracy: 0.9486922047163011\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.43926551938056946 accuracy: 0.9648075735748096 \n",
      "\n",
      "epoch: 11\n",
      "train \t\t loss mean 0.4212994873523712 accuracy: 0.9506744928431675\n",
      "validataion \t loss mean 0.4439074397087097 accuracy: 0.9580160526857378 \n",
      "\n",
      "epoch: 12\n",
      "train \t\t loss mean 0.4178023040294647 accuracy: 0.9528884769848626\n",
      "validataion \t loss mean 0.4400164783000946 accuracy: 0.963161144268368 \n",
      "\n",
      "epoch: 13\n",
      "train \t\t loss mean 0.41744720935821533 accuracy: 0.9538667490474719\n",
      "validataion \t loss mean 0.4380832314491272 accuracy: 0.9637785552582836 \n",
      "\n",
      "epoch: 14\n",
      "train \t\t loss mean 0.41565778851509094 accuracy: 0.9561579651941098\n",
      "validataion \t loss mean 0.43951284885406494 accuracy: 0.9635727515949783 \n",
      "\n",
      "epoch: 15\n",
      "train \t\t loss mean 0.41497528553009033 accuracy: 0.9567243332303573\n",
      "validataion \t loss mean 0.4404500424861908 accuracy: 0.9643959662481992 \n",
      "\n",
      "epoch: 16\n",
      "train \t\t loss mean 0.4120403528213501 accuracy: 0.9584749253423952\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.43777066469192505 accuracy: 0.96521918090142 \n",
      "\n",
      "epoch: 17\n",
      "train \t\t loss mean 0.41153910756111145 accuracy: 0.9596848934198332\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.43432414531707764 accuracy: 0.9697468614941346 \n",
      "\n",
      "epoch: 18\n",
      "train \t\t loss mean 0.4103235602378845 accuracy: 0.9605087014725568\n",
      "validataion \t loss mean 0.4378226101398468 accuracy: 0.9689236468409138 \n",
      "\n",
      "epoch: 19\n",
      "train \t\t loss mean 0.4087993800640106 accuracy: 0.9617444135516424\n",
      "validataion \t loss mean 0.44041717052459717 accuracy: 0.9646017699115044 \n",
      "\n",
      "epoch: 20\n",
      "train \t\t loss mean 0.40831834077835083 accuracy: 0.9624395015961281\n",
      "validataion \t loss mean 0.44004231691360474 accuracy: 0.9676888248610825 \n",
      "\n",
      "epoch: 21\n",
      "train \t\t loss mean 0.4078628122806549 accuracy: 0.9628256616208424\n",
      "validataion \t loss mean 0.43742305040359497 accuracy: 0.9689236468409138 \n",
      "\n",
      "epoch: 22\n",
      "train \t\t loss mean 0.4070016145706177 accuracy: 0.9637781896818042\n",
      "validataion \t loss mean 0.4411024749279022 accuracy: 0.9678946285243877 \n",
      "\n",
      "epoch: 23\n",
      "train \t\t loss mean 0.4057767391204834 accuracy: 0.9646019977345278\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.436372309923172 accuracy: 0.9720107017904919 \n",
      "\n",
      "epoch: 24\n",
      "train \t\t loss mean 0.4054391086101532 accuracy: 0.9648336937493563\n",
      "validataion \t loss mean 0.45397230982780457 accuracy: 0.9584276600123482 \n",
      "\n",
      "epoch: 25\n",
      "train \t\t loss mean 0.40372538566589355 accuracy: 0.9671506538976419\n",
      "validataion \t loss mean 0.4541134238243103 accuracy: 0.9598682856554847 \n",
      "\n",
      "epoch: 26\n",
      "train \t\t loss mean 0.40349146723747253 accuracy: 0.9671506538976419\n",
      "validataion \t loss mean 0.43652600049972534 accuracy: 0.9715990944638815 \n",
      "\n",
      "epoch: 27\n",
      "train \t\t loss mean 0.40262219309806824 accuracy: 0.9678199979404799\n",
      "validataion \t loss mean 0.4526364803314209 accuracy: 0.9621321259518419 \n",
      "\n",
      "epoch: 28\n",
      "train \t\t loss mean 0.4015282690525055 accuracy: 0.9695191020492225\n",
      "validataion \t loss mean 0.4387187957763672 accuracy: 0.9695410578308293 \n",
      "\n",
      "epoch: 29\n",
      "train \t\t loss mean 0.4010823369026184 accuracy: 0.9692359180310988\n",
      "validataion \t loss mean 0.44895243644714355 accuracy: 0.9658365918913356 \n",
      "\n",
      "epoch: 30\n",
      "train \t\t loss mean 0.40079987049102783 accuracy: 0.9704201421068891\n",
      "validataion \t loss mean 0.48974549770355225 accuracy: 0.9538999794196337 \n",
      "\n",
      "epoch: 31\n",
      "train \t\t loss mean 0.40045440196990967 accuracy: 0.9711924621563176\n",
      "validataion \t loss mean 0.46780070662498474 accuracy: 0.9633669479316732 \n",
      "\n",
      "epoch: 32\n",
      "train \t\t loss mean 0.3992045223712921 accuracy: 0.9718103181958604\n",
      "validataion \t loss mean 0.470723032951355 accuracy: 0.9625437332784523 \n",
      "\n",
      "epoch: 33\n",
      "train \t\t loss mean 0.3985487222671509 accuracy: 0.9720420142106889\n",
      "validataion \t loss mean 0.44200408458709717 accuracy: 0.9705700761473555 \n",
      "\n",
      "epoch: 34\n",
      "train \t\t loss mean 0.3980799913406372 accuracy: 0.9727628462568222\n",
      "validataion \t loss mean 0.4631364941596985 accuracy: 0.9650133772381149 \n",
      "\n",
      "epoch: 35\n",
      "train \t\t loss mean 0.3979995548725128 accuracy: 0.9729430542683555\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.4352746307849884 accuracy: 0.9746861494134595 \n",
      "\n",
      "epoch: 36\n",
      "train \t\t loss mean 0.3978535234928131 accuracy: 0.973174750283184\n",
      "validataion \t loss mean 0.4661828279495239 accuracy: 0.9660423955546409 \n",
      "\n",
      "epoch: 37\n",
      "train \t\t loss mean 0.39730530977249146 accuracy: 0.9741272783441458\n",
      "validataion \t loss mean 0.4362404942512512 accuracy: 0.9740687384235439 \n",
      "\n",
      "epoch: 38\n",
      "train \t\t loss mean 0.39658504724502563 accuracy: 0.9746679023787458\n",
      "validataion \t loss mean 0.47403478622436523 accuracy: 0.9648075735748096 \n",
      "\n",
      "epoch: 39\n",
      "train \t\t loss mean 0.3960583209991455 accuracy: 0.9755174544331171\n",
      "validataion \t loss mean 0.4708555042743683 accuracy: 0.9674830211977773 \n",
      "\n",
      "epoch: 40\n",
      "train \t\t loss mean 0.3960705101490021 accuracy: 0.9753115024199361\n",
      "validataion \t loss mean 0.435791939496994 accuracy: 0.9738629347602388 \n",
      "\n",
      "epoch: 41\n",
      "train \t\t loss mean 0.3952164053916931 accuracy: 0.9759551024611266\n",
      "validataion \t loss mean 0.4759003520011902 accuracy: 0.9606915003087055 \n",
      "\n",
      "epoch: 42\n",
      "train \t\t loss mean 0.3943181037902832 accuracy: 0.9770106065286788\n",
      "validataion \t loss mean 0.5194732546806335 accuracy: 0.9506071208067504 \n",
      "\n",
      "epoch: 43\n",
      "train \t\t loss mean 0.3940652012825012 accuracy: 0.9769076305220884\n",
      "validataion \t loss mean 0.4597855508327484 accuracy: 0.9713932908005762 \n",
      "\n",
      "epoch: 44\n",
      "train \t\t loss mean 0.3936261832714081 accuracy: 0.977731438574812\n",
      "validataion \t loss mean 0.469819039106369 accuracy: 0.9666598065445565 \n",
      "\n",
      "epoch: 45\n",
      "train \t\t loss mean 0.3939828872680664 accuracy: 0.9778859025846978\n",
      "validataion \t loss mean 0.4605225920677185 accuracy: 0.9705700761473555 \n",
      "\n",
      "epoch: 46\n",
      "train \t\t loss mean 0.39378124475479126 accuracy: 0.978066110596231\n",
      "validataion \t loss mean 0.46133196353912354 accuracy: 0.9730397201070179 \n",
      "\n",
      "epoch: 47\n",
      "train \t\t loss mean 0.39224812388420105 accuracy: 0.9794047986819071\n",
      "validataion \t loss mean 0.4611830413341522 accuracy: 0.9720107017904919 \n",
      "\n",
      "epoch: 48\n",
      "train \t\t loss mean 0.3931458294391632 accuracy: 0.9789156626506024\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.4495090842247009 accuracy: 0.9765383823832064 \n",
      "\n",
      "epoch: 49\n",
      "train \t\t loss mean 0.3923899233341217 accuracy: 0.9789671506538976\n",
      "validataion \t loss mean 0.49302253127098083 accuracy: 0.9650133772381149 \n",
      "\n",
      "epoch: 50\n",
      "train \t\t loss mean 0.3926299512386322 accuracy: 0.9799196787148594\n",
      "validataion \t loss mean 0.4644930064678192 accuracy: 0.9715990944638815 \n",
      "\n",
      "epoch: 51\n",
      "train \t\t loss mean 0.3916964530944824 accuracy: 0.9794562866852023\n",
      "validataion \t loss mean 0.4842674732208252 accuracy: 0.970158468820745 \n",
      "\n",
      "epoch: 52\n",
      "train \t\t loss mean 0.3916469216346741 accuracy: 0.9797394707033261\n",
      "validataion \t loss mean 0.4964785575866699 accuracy: 0.9648075735748096 \n",
      "\n",
      "epoch: 53\n",
      "train \t\t loss mean 0.3913291394710541 accuracy: 0.9805632787560499\n",
      "validataion \t loss mean 0.45934098958969116 accuracy: 0.9755093640666804 \n",
      "\n",
      "epoch: 54\n",
      "train \t\t loss mean 0.3909873962402344 accuracy: 0.9807177427659355\n",
      "validataion \t loss mean 0.47696778178215027 accuracy: 0.9726281127804075 \n",
      "\n",
      "epoch: 55\n",
      "train \t\t loss mean 0.39122137427330017 accuracy: 0.9807949747708784\n",
      "validataion \t loss mean 0.4679267406463623 accuracy: 0.9728339164437126 \n",
      "\n",
      "epoch: 56\n",
      "train \t\t loss mean 0.39126160740852356 accuracy: 0.9813870868087735\n",
      "validataion \t loss mean 0.5251175761222839 accuracy: 0.9600740893187899 \n",
      "\n",
      "epoch: 57\n",
      "train \t\t loss mean 0.3901430070400238 accuracy: 0.9815672948203069\n",
      "validataion \t loss mean 0.4906727373600006 accuracy: 0.9681004321876929 \n",
      "\n",
      "epoch: 58\n",
      "train \t\t loss mean 0.39026471972465515 accuracy: 0.982030686849964\n",
      "validataion \t loss mean 0.5129173994064331 accuracy: 0.9666598065445565 \n",
      "\n",
      "epoch: 59\n",
      "train \t\t loss mean 0.38936346769332886 accuracy: 0.9830089589125733\n",
      "validataion \t loss mean 0.5489602088928223 accuracy: 0.958221856349043 \n",
      "\n",
      "epoch: 60\n",
      "train \t\t loss mean 0.3898625373840332 accuracy: 0.9824425908763258\n",
      "validataion \t loss mean 0.5024047493934631 accuracy: 0.9728339164437126 \n",
      "\n",
      "epoch: 61\n",
      "train \t\t loss mean 0.3898431956768036 accuracy: 0.9820049428483163\n",
      "validataion \t loss mean 0.5375256538391113 accuracy: 0.9623379296151472 \n",
      "\n",
      "epoch: 62\n",
      "train \t\t loss mean 0.38930851221084595 accuracy: 0.9827515188960972\n",
      "validataion \t loss mean 0.5464638471603394 accuracy: 0.9596624819921794 \n",
      "\n",
      "epoch: 63\n",
      "train \t\t loss mean 0.3898466229438782 accuracy: 0.9830604469158686\n",
      "validataion \t loss mean 0.52251797914505 accuracy: 0.9709816834739659 \n",
      "\n",
      "epoch: 64\n",
      "train \t\t loss mean 0.3887910544872284 accuracy: 0.9832663989290495\n",
      "validataion \t loss mean 0.546202540397644 accuracy: 0.9604856966454003 \n",
      "\n",
      "epoch: 65\n",
      "train \t\t loss mean 0.38929086923599243 accuracy: 0.98336937493564\n",
      "validataion \t loss mean 0.5375333428382874 accuracy: 0.9660423955546409 \n",
      "\n",
      "epoch: 66\n",
      "train \t\t loss mean 0.3890884220600128 accuracy: 0.983704046957059\n",
      "validataion \t loss mean 0.5313652753829956 accuracy: 0.9654249845647253 \n",
      "\n",
      "epoch: 67\n",
      "train \t\t loss mean 0.3887023329734802 accuracy: 0.9841931829883637\n",
      "validataion \t loss mean 0.5303589105606079 accuracy: 0.9598682856554847 \n",
      "\n",
      "epoch: 68\n",
      "train \t\t loss mean 0.3882914185523987 accuracy: 0.9840902069817733\n",
      "validataion \t loss mean 0.459102600812912 accuracy: 0.976126775056596 \n",
      "\n",
      "epoch: 69\n",
      "train \t\t loss mean 0.38784629106521606 accuracy: 0.9843219029966018\n",
      "validataion \t loss mean 0.5430012345314026 accuracy: 0.9648075735748096 \n",
      "\n",
      "epoch: 70\n",
      "train \t\t loss mean 0.38843366503715515 accuracy: 0.9841674389867161\n",
      "validataion \t loss mean 0.5261598229408264 accuracy: 0.9709816834739659 \n",
      "\n",
      "epoch: 71\n",
      "train \t\t loss mean 0.3878181576728821 accuracy: 0.9847852950262589\n",
      "validataion \t loss mean 0.5354856252670288 accuracy: 0.9668656102078617 \n",
      "\n",
      "epoch: 72\n",
      "train \t\t loss mean 0.3878536522388458 accuracy: 0.9849912470394399\n",
      "validataion \t loss mean 0.4945066273212433 accuracy: 0.9695410578308293 \n",
      "\n",
      "epoch: 73\n",
      "train \t\t loss mean 0.38770240545272827 accuracy: 0.9851457110493255\n",
      "validataion \t loss mean 0.5237111449241638 accuracy: 0.9713932908005762 \n",
      "\n",
      "epoch: 74\n",
      "train \t\t loss mean 0.387228786945343 accuracy: 0.9854288950674492\n",
      "validataion \t loss mean 0.5189399719238281 accuracy: 0.9685120395143033 \n",
      "\n",
      "epoch: 75\n",
      "train \t\t loss mean 0.386989951133728 accuracy: 0.9859695191020492\n",
      "validataion \t loss mean 0.535423755645752 accuracy: 0.9672772175344722 \n",
      "\n",
      "epoch: 76\n",
      "train \t\t loss mean 0.3867749869823456 accuracy: 0.9857635670888683\n",
      "NEW RECODE!\n",
      "validataion \t loss mean 0.45286014676094055 accuracy: 0.9796254373327845 \n",
      "\n",
      "epoch: 77\n",
      "train \t\t loss mean 0.38637933135032654 accuracy: 0.9863041911234682\n",
      "validataion \t loss mean 0.5428953170776367 accuracy: 0.96521918090142 \n",
      "\n",
      "epoch: 78\n",
      "train \t\t loss mean 0.38743722438812256 accuracy: 0.9856348470806302\n",
      "validataion \t loss mean 0.5771819949150085 accuracy: 0.9588392673389586 \n",
      "\n",
      "epoch: 79\n",
      "train \t\t loss mean 0.3869437873363495 accuracy: 0.9860724951086397\n",
      "validataion \t loss mean 0.5710850954055786 accuracy: 0.9617205186252316 \n",
      "\n",
      "epoch: 80\n",
      "train \t\t loss mean 0.3865734934806824 accuracy: 0.9865616311399444\n",
      "validataion \t loss mean 0.5539548397064209 accuracy: 0.9676888248610825 \n",
      "\n",
      "epoch: 81\n",
      "train \t\t loss mean 0.3870740532875061 accuracy: 0.9861239831119349\n",
      "validataion \t loss mean 0.5056082010269165 accuracy: 0.9713932908005762 \n",
      "\n",
      "epoch: 82\n",
      "train \t\t loss mean 0.3866557478904724 accuracy: 0.986458655133354\n",
      "validataion \t loss mean 0.575788676738739 accuracy: 0.9611031076353159 \n",
      "\n",
      "epoch: 83\n",
      "train \t\t loss mean 0.3858031630516052 accuracy: 0.9871794871794872\n",
      "validataion \t loss mean 0.5290976762771606 accuracy: 0.9633669479316732 \n",
      "\n",
      "epoch: 84\n",
      "train \t\t loss mean 0.3859865665435791 accuracy: 0.9869992791679538\n",
      "validataion \t loss mean 0.502414345741272 accuracy: 0.9744803457501543 \n",
      "\n",
      "epoch: 85\n",
      "train \t\t loss mean 0.3851485848426819 accuracy: 0.9872824631860776\n",
      "validataion \t loss mean 0.5619216561317444 accuracy: 0.9664540028812513 \n",
      "\n",
      "epoch: 86\n",
      "train \t\t loss mean 0.38607513904571533 accuracy: 0.9872824631860776\n",
      "validataion \t loss mean 0.4983944892883301 accuracy: 0.9748919530767648 \n",
      "\n",
      "epoch: 87\n",
      "train \t\t loss mean 0.38586708903312683 accuracy: 0.987591391205849\n",
      "validataion \t loss mean 0.5246520638465881 accuracy: 0.9726281127804075 \n",
      "\n",
      "epoch: 88\n",
      "train \t\t loss mean 0.38646450638771057 accuracy: 0.9871794871794872\n",
      "validataion \t loss mean 0.5193073153495789 accuracy: 0.9736571310969335 \n",
      "\n",
      "epoch: 89\n",
      "train \t\t loss mean 0.3855237066745758 accuracy: 0.9878745752239728\n",
      "validataion \t loss mean 0.5247007012367249 accuracy: 0.964190162584894 \n",
      "\n",
      "epoch: 90\n",
      "train \t\t loss mean 0.38577622175216675 accuracy: 0.9877201112140871\n",
      "validataion \t loss mean 0.5051538348197937 accuracy: 0.9738629347602388 \n",
      "\n",
      "epoch: 91\n",
      "train \t\t loss mean 0.3854373097419739 accuracy: 0.9880805272371538\n",
      "validataion \t loss mean 0.568642795085907 accuracy: 0.9615147149619263 \n",
      "\n",
      "epoch: 92\n",
      "train \t\t loss mean 0.38563382625579834 accuracy: 0.9881835032437442\n",
      "validataion \t loss mean 0.4883810877799988 accuracy: 0.9753035604033752 \n",
      "\n",
      "epoch: 93\n",
      "train \t\t loss mean 0.38530704379081726 accuracy: 0.9885181752651632\n",
      "validataion \t loss mean 0.5357531905174255 accuracy: 0.9699526651574398 \n",
      "\n",
      "epoch: 94\n",
      "train \t\t loss mean 0.3854024112224579 accuracy: 0.9885181752651632\n",
      "validataion \t loss mean 0.5250064730644226 accuracy: 0.9753035604033752 \n",
      "\n",
      "epoch: 95\n",
      "train \t\t loss mean 0.38455304503440857 accuracy: 0.9885181752651632\n",
      "validataion \t loss mean 0.5840275287628174 accuracy: 0.9650133772381149 \n",
      "\n",
      "epoch: 96\n",
      "train \t\t loss mean 0.3846507668495178 accuracy: 0.9886468952734013\n",
      "validataion \t loss mean 0.5677469968795776 accuracy: 0.9658365918913356 \n",
      "\n",
      "epoch: 97\n",
      "train \t\t loss mean 0.38495346903800964 accuracy: 0.9887756152816394\n",
      "validataion \t loss mean 0.5234179496765137 accuracy: 0.9736571310969335 \n",
      "\n",
      "epoch: 98\n",
      "train \t\t loss mean 0.38487735390663147 accuracy: 0.9887498712799918\n",
      "validataion \t loss mean 0.5483021140098572 accuracy: 0.9664540028812513 \n",
      "\n",
      "epoch: 99\n",
      "train \t\t loss mean 0.3851904273033142 accuracy: 0.9884151992585728\n",
      "validataion \t loss mean 0.4965691566467285 accuracy: 0.9773615970364272 \n",
      "\n",
      "best validation acc = 0.9796254373327845, in epoch 76\n"
     ]
    }
   ],
   "source": [
    "epoches = 100\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = -1\n",
    "\n",
    "best_acc_pred = []\n",
    "train_acc_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for i in range(epoches):\n",
    "    # Train\n",
    "    loss_sum = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    model.train()\n",
    "    for e_num, (x,y) in enumerate(train_dataloader):\n",
    "        x, y = x.type(torch.FloatTensor).to(device), y.type(torch.FloatTensor).to(device)\n",
    "        model.zero_grad()\n",
    "        pred_y = model(x)\n",
    "        \n",
    "        loss=criterion(pred_y,y)\n",
    "        loss_sum+=loss.detach()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        true_labels.extend(y.cpu().numpy())\n",
    "        pred_labels.extend(np.around(pred_y.cpu().detach().numpy()))\n",
    "        \n",
    "        \n",
    "    acc=accuracy_score(true_labels,pred_labels)\n",
    "    print(f'epoch: {i}')\n",
    "    print(f'train \\t\\t loss mean {loss_sum/e_num} accuracy: {acc}')\n",
    "    \n",
    "    # Valid\n",
    "    loss_sum=0\n",
    "    true_labels=[]\n",
    "    pred_labels=[]\n",
    "    model.eval()\n",
    "    for e_num, (x,y) in enumerate(val_dataloader):\n",
    "        x, y = x.type(torch.FloatTensor).to(device), y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        pred_y = model(x)\n",
    "        loss=criterion(pred_y,y)\n",
    "        \n",
    "        loss_sum+=loss.detach()\n",
    "        \n",
    "        true_labels.extend(y.cpu().numpy())\n",
    "        pred_labels.extend(np.around(pred_y.cpu().detach().numpy()))\n",
    "        \n",
    "        \n",
    "    acc=accuracy_score(true_labels,pred_labels)\n",
    "    if best_val_acc < acc:\n",
    "        print(\"NEW RECODE!\")\n",
    "        best_acc_pred = pred_labels\n",
    "        best_val_acc = acc\n",
    "        best_epoch = i\n",
    "    print(f'validataion \\t loss mean {loss_sum/e_num} accuracy: {acc} ',end='\\n\\n')\n",
    "    \n",
    "print(f'best validation acc = {best_val_acc}, in epoch {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fper, tper):\n",
    "    plt.plot(fper, tper, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bang/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fper, tper, thresholds = roc_curve(true_labels,best_acc_pred)\n",
    "plot_roc_curve(fper, tper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
